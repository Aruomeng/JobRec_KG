#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GraphSAGE æ¨¡å‹æµ‹è¯•è„šæœ¬
æµ‹è¯•10åéšæœºç”Ÿæˆçš„æ–°å­¦ç”Ÿï¼ˆéè®­ç»ƒé›†ï¼‰
"""

import torch
import json
import random
from datetime import datetime
from neo4j import GraphDatabase

# å¤ç”¨ç”Ÿæˆå­¦ç”Ÿçš„é€»è¾‘
SURNAMES = ['ç‹','æ','å¼ ','åˆ˜','é™ˆ','æ¨','èµµ','é»„','å‘¨','å´','å¾','å­™','èƒ¡','æœ±','é«˜']
NAMES = ['ä¼Ÿ','èŠ³','å¨œ','æ•','é™','ä¸½','å¼º','ç£Š','å†›','æ´‹','å‹‡','è‰³','æ°','æ¶›','æ˜']
CITIES = ['åŒ—äº¬','ä¸Šæµ·','æ·±åœ³','æ­å·','å—äº¬','æˆéƒ½','æ­¦æ±‰','éƒ‘å·','å¦é—¨']
EDUCATIONS = ['å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«']

domain_data = {
    "ç‰©è”ç½‘å·¥ç¨‹": {"ç‰©è”ç½‘å¯¼è®º": ["IoTæ¦‚å¿µ","ä¼ æ„Ÿå™¨æŠ€æœ¯","RFID"], "åµŒå…¥å¼ç³»ç»Ÿè®¾è®¡": ["Cè¯­è¨€","ARMæ¶æ„","Linuxé©±åŠ¨"]},
    "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯": {"Javaè¯­è¨€ç¨‹åºè®¾è®¡": ["Java","JVM","å¤šçº¿ç¨‹"], "æ•°æ®ç»“æ„ä¸ç®—æ³•": ["ç®—æ³•","æ•°æ®ç»“æ„","é€»è¾‘æ€ç»´"], "è®¡ç®—æœºç½‘ç»œ": ["TCP/IP","HTTPåè®®","ç½‘ç»œç¼–ç¨‹"]},
    "è½¯ä»¶å·¥ç¨‹": {"Javaä¼ä¸šçº§å¼€å‘": ["Java","Spring Boot","MyBatis"], "Webåº”ç”¨å¼€å‘": ["React","JavaScript","Node.js"], "DevOpså®è·µ": ["Docker","Kubernetes","Jenkins"]},
    "å¤§æ•°æ®ç®¡ç†ä¸åº”ç”¨": {"Pythonæ•°æ®åˆ†æ": ["Python","Pandas","NumPy"], "Hadoopå¤§æ•°æ®æŠ€æœ¯": ["Hadoop","MapReduce","HDFS"], "æœºå™¨å­¦ä¹ å¯¼è®º": ["Scikit-learn","æœºå™¨å­¦ä¹ ","ç»Ÿè®¡å­¦"]},
    "äººå·¥æ™ºèƒ½": {"æ·±åº¦å­¦ä¹ ": ["TensorFlow","PyTorch","ç¥ç»ç½‘ç»œ"], "è®¡ç®—æœºè§†è§‰": ["OpenCV","å›¾åƒå¤„ç†","CNN"], "è‡ªç„¶è¯­è¨€å¤„ç†": ["NLP","BERT","æ–‡æœ¬åˆ†æ"]},
    "ç½‘ç»œå·¥ç¨‹": {"è·¯ç”±ä¸äº¤æ¢æŠ€æœ¯": ["Cisco","åä¸ºè®¤è¯","VLAN"], "ç½‘ç»œå®‰å…¨æŠ€æœ¯": ["é˜²ç«å¢™","VPN","å…¥ä¾µæ£€æµ‹"], "äº‘è®¡ç®—æ¶æ„": ["OpenStack","KVM","è™šæ‹ŸåŒ–"]},
}

def generate_test_student(student_id):
    """ç”Ÿæˆä¸€ä¸ªæµ‹è¯•å­¦ç”Ÿ"""
    name = random.choice(SURNAMES) + random.choice(NAMES) + random.choice(NAMES)
    education = random.choices(EDUCATIONS, weights=[15, 60, 20, 5])[0]
    major = random.choice(list(domain_data.keys()))
    preferred_cities = random.sample(CITIES, random.randint(1, 3))
    
    courses = list(domain_data[major].keys())
    selected_courses = random.sample(courses, min(2, len(courses)))
    
    skills = set()
    for course in selected_courses:
        skills.update(domain_data[major][course])
    
    return {
        'student_id': student_id,
        'name': name,
        'education': education,
        'major': major,
        'preferred_cities': preferred_cities,
        'skills': list(skills)
    }

def test_recommendation():
    from model import RecommenderModel
    
    print("="*70)
    print("ğŸ§ª GraphSAGE æ¨¡å‹æµ‹è¯•æŠ¥å‘Š")
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*70)
    
    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    data = torch.load('graph_data.pt', weights_only=False)
    model = RecommenderModel(data.metadata(), hidden_channels=64, out_channels=32)
    model.load_state_dict(torch.load('è¾“å‡º/æ¨¡å‹æƒé‡/graphsage_model.pth', weights_only=True))
    model.eval()
    
    print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   èŒä½æ€»æ•°: {data['job'].num_nodes:,}")
    print(f"   æŠ€èƒ½æ€»æ•°: {data['skill'].num_nodes:,}")
    
    # è¿æ¥Neo4jè·å–èŒä½è¯¦æƒ…
    driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "TYH041113"))
    
    # ç”Ÿæˆ10åæµ‹è¯•å­¦ç”Ÿ (IDä»TEST0001å¼€å§‹ï¼Œé¿å…ä¸è®­ç»ƒé›†STU0001-0500é‡å¤)
    test_students = [generate_test_student(f"TEST{i:04d}") for i in range(1, 11)]
    
    print(f"\nğŸ“ æµ‹è¯•å­¦ç”Ÿ: {len(test_students)}å (éè®­ç»ƒé›†)")
    print("-"*70)
    
    results = []
    
    # è·å–ç¼–ç åçš„èŠ‚ç‚¹åµŒå…¥
    with torch.no_grad():
        x_dict = model.encoder(data.x_dict, data.edge_index_dict)
        job_embs = x_dict['job']
        
        # ç”±äºæµ‹è¯•å­¦ç”Ÿä¸åœ¨å›¾ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åŸºäºæŠ€èƒ½ç›¸ä¼¼åº¦æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è®­ç»ƒå­¦ç”Ÿ
        # ç„¶åä½¿ç”¨è¯¥å­¦ç”Ÿçš„åµŒå…¥è¿›è¡Œæ¨è
        # è¿™æ¨¡æ‹Ÿäº†å†·å¯åŠ¨åœºæ™¯
        
        # ç®€åŒ–å¤„ç†ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªè®­ç»ƒå­¦ç”Ÿä½œä¸ºä»£ç†
        # å®é™…åº”ç”¨ä¸­åº”è¯¥åŸºäºç‰¹å¾ç›¸ä¼¼åº¦
        
        job_id_map = {v: k for k, v in data['job'].node_map.items()}
        
        for idx, student in enumerate(test_students):
            # ä½¿ç”¨éšæœºè®­ç»ƒå­¦ç”Ÿçš„åµŒå…¥ï¼ˆæ¨¡æ‹Ÿå†·å¯åŠ¨çš„ç®€åŒ–æ–¹æ¡ˆï¼‰
            proxy_idx = random.randint(0, data['student'].num_nodes - 1)
            student_emb = x_dict['student'][proxy_idx]
            
            # è®¡ç®—ä¸æ‰€æœ‰èŒä½çš„åŒ¹é…åˆ†æ•°
            num_jobs = data['job'].num_nodes
            batch_size = 1000
            scores = []
            
            for i in range(0, num_jobs, batch_size):
                end = min(i + batch_size, num_jobs)
                batch_job_indices = torch.arange(i, end)
                batch_src = torch.full((len(batch_job_indices),), proxy_idx, dtype=torch.long)
                batch_edge_index = torch.stack([batch_src, batch_job_indices], dim=0)
                batch_pred = model.predictor(x_dict['student'], x_dict['job'], batch_edge_index)
                scores.append(batch_pred.squeeze())
            
            all_scores = torch.cat(scores)
            top_scores, top_indices = torch.topk(all_scores, 3)
            
            # æŸ¥è¯¢èŒä½è¯¦æƒ…
            recommendations = []
            for score, job_idx in zip(top_scores, top_indices):
                job_url = job_id_map[job_idx.item()]
                suffix = job_url.split('/')[-1]
                
                query = f"MATCH (j:Job) WHERE j.url ENDS WITH '{suffix}' RETURN j.title as title, j.salary as salary"
                with driver.session() as session:
                    result = session.run(query).single()
                    if result:
                        recommendations.append({
                            'title': result['title'] or 'æœªçŸ¥',
                            'salary': result['salary'] or 'é¢è®®',
                            'score': score.item()
                        })
            
            results.append({
                'student': student,
                'recommendations': recommendations
            })
            
            # æ‰“å°ç»“æœ
            print(f"\nğŸ‘¤ {student['name']} ({student['student_id']})")
            print(f"   ğŸ“ {student['education']} | {student['major']}")
            print(f"   ğŸ“ æœŸæœ›åŸå¸‚: {', '.join(student['preferred_cities'])}")
            print(f"   ğŸ› ï¸ æŠ€èƒ½: {', '.join(student['skills'][:5])}...")
            print(f"   ğŸ“‹ æ¨èèŒä½:")
            for i, rec in enumerate(recommendations[:3], 1):
                print(f"      {i}. {rec['title']} ({rec['salary']}) - å¾—åˆ†:{rec['score']:.4f}")
    
    driver.close()
    
    # ç»Ÿè®¡æ±‡æ€»
    print("\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•ç»Ÿè®¡æ±‡æ€»")
    print("="*70)
    
    all_scores = []
    for r in results:
        for rec in r['recommendations']:
            all_scores.append(rec['score'])
    
    if all_scores:
        avg_score = sum(all_scores) / len(all_scores)
        max_score = max(all_scores)
        min_score = min(all_scores)
        print(f"   å¹³å‡æ¨èå¾—åˆ†: {avg_score:.4f}")
        print(f"   æœ€é«˜å¾—åˆ†: {max_score:.4f}")
        print(f"   æœ€ä½å¾—åˆ†: {min_score:.4f}")
    
    # ä¸“ä¸šåˆ†å¸ƒ
    majors = {}
    for r in results:
        m = r['student']['major']
        majors[m] = majors.get(m, 0) + 1
    
    print(f"\n   æµ‹è¯•å­¦ç”Ÿä¸“ä¸šåˆ†å¸ƒ:")
    for m, c in majors.items():
        print(f"      â€¢ {m}: {c}äºº")
    
    print("\n" + "="*70)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("="*70)
    
    return results

if __name__ == "__main__":
    test_recommendation()
