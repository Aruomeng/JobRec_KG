import torch
import os
import json
import numpy as np

try:
    from data_loader import GraphDataLoader
    from model import RecommenderModel
except ImportError:
    exit(1)

def recommend(student_id_str, top_k=5):
    # 1. åŠ è½½æ•°æ®
    data_path = 'graph_data.pt'
    if not os.path.exists(data_path):
        print("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ train.py")
        return
        
    data = torch.load(data_path, weights_only=False)
    model_path = 'è¾“å‡º/æ¨¡å‹æƒé‡/graphsage_model.pth'
    
    # 2. åŠ è½½æ¨¡å‹
    model = RecommenderModel(data.metadata(), hidden_channels=64, out_channels=32)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    
    # 3. æŸ¥æ‰¾å­¦ç”ŸID
    if student_id_str not in data['student'].node_map:
        print(f"âŒ æ‰¾ä¸åˆ°å­¦ç”Ÿ: {student_id_str}")
        return
        
    s_idx = data['student'].node_map[student_id_str]
    num_jobs = data['job'].num_nodes
    
    # 4. é¢„æµ‹æ‰€æœ‰èŒä½çš„åˆ†æ•°
    # æ„é€  (Student, All_Jobs) è¾¹
    print(f"ğŸ” æ­£åœ¨ä¸º {student_id_str} è®¡ç®— {num_jobs} ä¸ªèŒä½çš„æ¨èåˆ†æ•°...")
    
    with torch.no_grad():
        # è·å–æ‰€æœ‰èŠ‚ç‚¹çš„ Embedding
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¼ å…¥æ•´ä¸ªå›¾ç»“æ„è¿›è¡Œç¼–ç 
        x_dict = model.encoder(data.x_dict, data.edge_index_dict)
        student_emb = x_dict['student'][s_idx] # [32]
        job_embs = x_dict['job']                # [num_jobs, 32]
        
        # è®¡ç®—ç›¸ä¼¼åº¦ (ç‚¹ç§¯)
        # (1, 32) * (32, num_jobs) -> (1, num_jobs)
        # ä½†modelæ˜¯æ‹¼æ¥çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬æ‰‹åŠ¨æ„å»ºbatché¢„æµ‹
        # ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨ç‚¹ç§¯æ¨¡æ‹Ÿ LinkPredictor çš„è¡Œä¸º (è‹¥ LinkPredictor æ˜¯ç®€å•çº¿æ€§å±‚)
        # è¿™é‡Œä¸ºäº†å‡†ç¡®ï¼Œæˆ‘ä»¬è¿˜æ˜¯è°ƒç”¨ predictor
        
        # æ‰¹é‡é¢„æµ‹ (åˆ†æ‰¹å¤„ç†é˜²æ­¢å†…å­˜æº¢å‡º)
        batch_size = 1000
        scores = []
        for i in range(0, num_jobs, batch_size):
            end = min(i + batch_size, num_jobs)
            batch_job_indices = torch.arange(i, end)
            batch_src = torch.full((len(batch_job_indices),), s_idx, dtype=torch.long)
            
            batch_edge_index = torch.stack([batch_src, batch_job_indices], dim=0)
            
            # ä½¿ç”¨ç¼–ç åçš„ç‰¹å¾è¿›è¡Œé¢„æµ‹
            batch_pred = model.predictor(x_dict['student'], x_dict['job'], batch_edge_index)
            scores.append(batch_pred.squeeze())
            
        all_scores = torch.cat(scores)
        
    # 5. è·å– Top-K
    top_scores, top_indices = torch.topk(all_scores, top_k)
    
    # 6. è§£æç»“æœ (åå‘æŸ¥Jobä¿¡æ¯)
    # åè½¬ job map
    job_id_map = {v: k for k, v in data['job'].node_map.items()}
    
    # åŠ è½½åŸå§‹èŒä½ä¿¡æ¯ï¼ˆè¿™ä¸€æ­¥åœ¨å®é™…ç³»ç»Ÿä¸­æ˜¯ä»DBæŸ¥ï¼‰
    # è¿™é‡Œæˆ‘ä»¬åªæ‰“å°IDå’Œåˆ†æ•°
    print(f"\nâœ… æ¨èç»“æœ (Top {top_k}):")
    print("-" * 50)
    for score, idx in zip(top_scores, top_indices):
        job_url = job_id_map[idx.item()]
        print(f"ğŸ”— èŒä½ID: {job_url[-20:]} | å¾—åˆ†: {score.item():.4f}")
    print("-" * 50)

if __name__ == "__main__":
    # æµ‹è¯•ç”Ÿæˆçš„ç¬¬ä¸€ä¸ªå­¦ç”Ÿ
    recommend("STU0001")
    # æµ‹è¯•ç”Ÿæˆçš„ç¬¬äºŒä¸ªå­¦ç”Ÿ
    recommend("STU0002")
