#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HybridRecommender: ä¸‰å±‚æ¼æ–—å¼æ··åˆæ¨èç³»ç»Ÿ
==========================================
Layer 1: å¿«é€Ÿå¬å› (Recall) - åŸºäºå‘é‡ç›¸ä¼¼åº¦
Layer 2: ç²¾æ’åº (Ranking) - åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹  
Layer 3: é‡æ’åº (Fusion) - ç¥ç»ç¬¦å·èåˆ + å¯è§£é‡Šæ€§

Author: Antigravity AI Agent
Date: 2026-01-13
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from neo4j import GraphDatabase
import warnings

# å°è¯•å¯¼å…¥faissï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨numpyæ›¿ä»£
try:
    import faiss
    USE_FAISS = False  # ç¦ç”¨ FAISS ä»¥é¿å… ARM64 Mac ä¸Šçš„å´©æºƒ
except ImportError:
    USE_FAISS = False
    warnings.warn("faiss not installed, using numpy for similarity search (slower)")


@dataclass
class RecommendationResult:
    """å•ä¸ªæ¨èç»“æœ"""
    job_id: str
    final_score: float
    deep_score: float  # æ·±åº¦å­¦ä¹ å¾—åˆ†
    skill_score: float  # æŠ€èƒ½åŒ¹é…å¾—åˆ†
    rule_score: float  # è§„åˆ™å¾—åˆ†
    matched_skills: List[str]  # åŒ¹é…çš„æŠ€èƒ½
    explanation: str  # æ¨èç†ç”±


class HybridRecommender:
    """
    ä¸‰å±‚æ¼æ–—å¼æ··åˆæ¨èå™¨
    
    Attributes:
        node_embeddings: èŠ‚ç‚¹åµŒå…¥å­—å…¸ {id: tensor}
        link_predictor: é¢„è®­ç»ƒçš„é“¾è·¯é¢„æµ‹æ¨¡å‹
        neo4j_driver: Neo4jæ•°æ®åº“é©±åŠ¨
        job_mapping: Jobç´¢å¼•åˆ°IDçš„æ˜ å°„
    """
    
    def __init__(
        self,
        node_embeddings: Dict[str, torch.Tensor],
        link_predictor: torch.nn.Module,
        neo4j_driver: Any,
        job_mapping: Dict[int, str],
        embedding_dim: int = 32
    ):
        """
        åˆå§‹åŒ–æ··åˆæ¨èå™¨
        
        Args:
            node_embeddings: æ‰€æœ‰èŠ‚ç‚¹çš„åµŒå…¥å‘é‡
            link_predictor: é¢„è®­ç»ƒçš„é“¾è·¯é¢„æµ‹æ¨¡å‹
            neo4j_driver: Neo4jé©±åŠ¨å®ä¾‹
            job_mapping: ç´¢å¼•åˆ°Job IDçš„æ˜ å°„
            embedding_dim: åµŒå…¥å‘é‡ç»´åº¦
        """
        self.embeddings = node_embeddings
        self.predictor = link_predictor
        self.driver = neo4j_driver
        self.job_mapping = job_mapping
        self.embedding_dim = embedding_dim
        
        # æå–æ‰€æœ‰JobåµŒå…¥å¹¶æ„å»ºç´¢å¼•
        self._build_job_index()
        
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.predictor.eval()
        
        print(f"âœ… HybridRecommender åˆå§‹åŒ–å®Œæˆ")
        print(f"   Jobæ•°é‡: {len(self.job_mapping)}")
        print(f"   åµŒå…¥ç»´åº¦: {embedding_dim}")
        print(f"   ä½¿ç”¨FAISS: {USE_FAISS}")
    
    def _build_job_index(self):
        """æ„å»ºJobå‘é‡ç´¢å¼•ç”¨äºå¿«é€Ÿæ£€ç´¢"""
        # æ”¶é›†æ‰€æœ‰Jobçš„åµŒå…¥
        job_ids = sorted(self.job_mapping.keys())
        job_embeddings = []
        
        for idx in job_ids:
            job_id = self.job_mapping[idx]
            if job_id in self.embeddings:
                emb = self.embeddings[job_id]
            elif idx in self.embeddings:
                emb = self.embeddings[idx]
            else:
                # ä½¿ç”¨éšæœºå‘é‡ä½œä¸ºfallback
                emb = torch.randn(self.embedding_dim)
            
            if isinstance(emb, torch.Tensor):
                emb = emb.detach().cpu().numpy()
            job_embeddings.append(emb)
        
        self.job_embeddings_np = np.array(job_embeddings, dtype=np.float32)
        self.job_indices = job_ids
        
        # å½’ä¸€åŒ–ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦
        norms = np.linalg.norm(self.job_embeddings_np, axis=1, keepdims=True)
        norms[norms == 0] = 1  # é˜²æ­¢é™¤é›¶
        self.job_embeddings_normalized = self.job_embeddings_np / norms
        
        if USE_FAISS:
            # ä½¿ç”¨FAISSæ„å»ºç´¢å¼• (å†…ç§¯ = ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå› ä¸ºå·²å½’ä¸€åŒ–)
            self.index = faiss.IndexFlatIP(self.embedding_dim)
            self.index.add(self.job_embeddings_normalized)
        else:
            self.index = None
    
    # ==================== Layer 1: å¿«é€Ÿå¬å› ====================
    def recall(self, student_id: str, top_k: int = 500, skills: List[str] = None) -> List[int]:
        """
        Layer 1: åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„å¿«é€Ÿå¬å›
        
        Args:
            student_id: å­¦ç”ŸID
            top_k: å¬å›æ•°é‡
            skills: ç”¨æˆ·æŠ€èƒ½åˆ—è¡¨ï¼ˆç”¨äºå†·å¯åŠ¨ç”¨æˆ·çš„åµŒå…¥ç”Ÿæˆï¼‰
            
        Returns:
            å€™é€‰Jobç´¢å¼•åˆ—è¡¨
        """
        # è·å–å­¦ç”ŸåµŒå…¥ï¼ˆæ”¯æŒåŸºäºæŠ€èƒ½çš„å›é€€ç”Ÿæˆï¼‰
        student_emb = self._get_student_embedding_with_skills(student_id, skills)
        
        if student_emb is None:
            # çœŸæ­£çš„å†·å¯åŠ¨ï¼ˆæ— åµŒå…¥ä¸”æ— æœ‰æ•ˆæŠ€èƒ½ï¼‰
            print(f"âš ï¸  å­¦ç”Ÿ {student_id} æ— åµŒå…¥ä¸”æ— æœ‰æ•ˆæŠ€èƒ½ï¼Œä½¿ç”¨å†·å¯åŠ¨ç­–ç•¥")
            return self._cold_start_recall(student_id, top_k)
        
        # å½’ä¸€åŒ–
        if isinstance(student_emb, torch.Tensor):
            student_emb = student_emb.detach().cpu().numpy()
        student_emb = student_emb.astype(np.float32).reshape(1, -1)
        norm = np.linalg.norm(student_emb)
        if norm > 0:
            student_emb = student_emb / norm
        
        if USE_FAISS and self.index is not None:
            # ä½¿ç”¨FAISSè¿›è¡Œæ£€ç´¢
            scores, indices = self.index.search(student_emb, min(top_k, len(self.job_indices)))
            return [self.job_indices[i] for i in indices[0]]
        else:
            # ä½¿ç”¨NumPyè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarities = np.dot(self.job_embeddings_normalized, student_emb.T).flatten()
            top_indices = np.argsort(similarities)[::-1][:top_k]
            return [self.job_indices[i] for i in top_indices]
    
    def _get_student_embedding(self, student_id: str) -> Optional[np.ndarray]:
        """è·å–å­¦ç”ŸåµŒå…¥å‘é‡"""
        if student_id in self.embeddings:
            return self.embeddings[student_id]
        # å°è¯•æ•°å­—ç´¢å¼•
        try:
            idx = int(student_id.replace('STU', '').replace('TEST', ''))
            if idx in self.embeddings:
                return self.embeddings[idx]
        except:
            pass
        return None
    
    def _get_student_embedding_with_skills(self, student_id: str, skills: List[str] = None) -> Optional[torch.Tensor]:
        """
        è·å–å­¦ç”ŸåµŒå…¥å‘é‡ï¼Œæ”¯æŒåŸºäºæŠ€èƒ½çš„å›é€€ç”Ÿæˆ
        
        å¯¹äºä¸åœ¨è®­ç»ƒæ•°æ®ä¸­çš„ç”¨æˆ·ï¼Œæ ¹æ®å…¶æŠ€èƒ½åµŒå…¥çš„å¹³å‡å€¼ç”Ÿæˆä¸´æ—¶ç”¨æˆ·ç”»åƒ
        
        Args:
            student_id: å­¦ç”ŸID
            skills: ç”¨æˆ·æŒæ¡çš„æŠ€èƒ½åˆ—è¡¨
            
        Returns:
            å­¦ç”ŸåµŒå…¥å‘é‡ï¼Œå¦‚æœæ— æ³•ç”Ÿæˆåˆ™è¿”å› None
        """
        # 1. ä¼˜å…ˆä½¿ç”¨ç¼“å­˜çš„åµŒå…¥ï¼ˆè®­ç»ƒæ•°æ®ä¸­çš„å­¦ç”Ÿï¼‰
        emb = self._get_student_embedding(student_id)
        if emb is not None:
            if isinstance(emb, np.ndarray):
                return torch.from_numpy(emb).float()
            return emb
        
        # 2. åŸºäºæŠ€èƒ½èšåˆç”Ÿæˆä¸´æ—¶åµŒå…¥ï¼ˆå†·å¯åŠ¨ç”¨æˆ·ï¼‰
        if skills:
            try:
                skill_embs = []
                for sk in skills:
                    # æŠ€èƒ½å¯èƒ½ä»¥ä¸åŒæ ¼å¼å­˜å‚¨
                    if sk in self.embeddings:
                        emb = self.embeddings[sk]
                        if isinstance(emb, torch.Tensor):
                            skill_embs.append(emb.detach().clone())
                        elif isinstance(emb, np.ndarray):
                            skill_embs.append(torch.from_numpy(emb.copy()).float())
                    elif f"skill_{sk}" in self.embeddings:
                        emb = self.embeddings[f"skill_{sk}"]
                        if isinstance(emb, torch.Tensor):
                            skill_embs.append(emb.detach().clone())
                        elif isinstance(emb, np.ndarray):
                            skill_embs.append(torch.from_numpy(emb.copy()).float())
                
                if skill_embs:
                    # å°†æŠ€èƒ½åµŒå…¥å †å å¹¶å–å¹³å‡
                    stacked = torch.stack(skill_embs)
                    avg_emb = torch.mean(stacked, dim=0)
                    print(f"ğŸ¯ ä¸º {student_id} åŸºäº {len(skill_embs)} ä¸ªæŠ€èƒ½ç”Ÿæˆä¸´æ—¶åµŒå…¥")
                    return avg_emb
            except Exception as e:
                print(f"âš ï¸ æŠ€èƒ½åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
        
        return None
    
    def _cold_start_recall(self, student_id: str, top_k: int) -> List[int]:
        """
        å†·å¯åŠ¨å¬å›ï¼šåŸºäºä¸“ä¸šçš„ç²—æ’
        TODO: å¯ä»¥é€šè¿‡Neo4jæŸ¥è¯¢å­¦ç”Ÿä¸“ä¸šï¼Œç„¶ååŒ¹é…ç›¸å…³èŒä½
        """
        # ç®€å•å®ç°ï¼šè¿”å›éšæœºèŒä½
        indices = list(self.job_indices)
        np.random.shuffle(indices)
        return indices[:top_k]
    
    # ==================== Layer 2: ç²¾æ’åº ====================
    def rank(
        self, 
        student_id: str, 
        candidate_jobs: List[int],
        student_emb: Optional[torch.Tensor] = None
    ) -> List[Tuple[int, float]]:
        """
        Layer 2: åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç²¾æ’åº
        
        Args:
            student_id: å­¦ç”ŸID
            candidate_jobs: å€™é€‰Jobç´¢å¼•åˆ—è¡¨
            student_emb: å¯é€‰çš„å­¦ç”ŸåµŒå…¥ï¼ˆé¿å…é‡å¤è·å–ï¼‰
            
        Returns:
            (job_idx, score) å…ƒç»„åˆ—è¡¨ï¼ŒæŒ‰åˆ†æ•°é™åºæ’åˆ—
        """
        if student_emb is None:
            student_emb = self._get_student_embedding(student_id)
            if student_emb is None:
                # æ— åµŒå…¥æ—¶è¿”å›éšæœºæ’åº
                return [(idx, 0.5) for idx in candidate_jobs]
        
        if isinstance(student_emb, np.ndarray):
            student_emb = torch.from_numpy(student_emb).float()
        
        # æ‰¹é‡é¢„æµ‹
        scores = []
        batch_size = 128
        
        with torch.no_grad():
            for i in range(0, len(candidate_jobs), batch_size):
                batch_jobs = candidate_jobs[i:i+batch_size]
                
                # è·å–JobåµŒå…¥
                job_embs = []
                for job_idx in batch_jobs:
                    job_id = self.job_mapping.get(job_idx, str(job_idx))
                    if job_id in self.embeddings:
                        job_embs.append(self.embeddings[job_id])
                    elif job_idx < len(self.job_embeddings_np):
                        job_embs.append(torch.from_numpy(self.job_embeddings_np[job_idx]))
                    else:
                        job_embs.append(torch.zeros(self.embedding_dim))
                
                job_embs = torch.stack([e if isinstance(e, torch.Tensor) else torch.from_numpy(e) 
                                        for e in job_embs]).float()
                
                # æ„å»ºè¾¹ç´¢å¼• (student -> jobs)
                student_embs = student_emb.unsqueeze(0).expand(len(batch_jobs), -1)
                
                # æ‹¼æ¥ç‰¹å¾å¹¶é¢„æµ‹
                combined = torch.cat([student_embs, job_embs], dim=-1)
                
                # ä½¿ç”¨predictorçš„çº¿æ€§å±‚
                if hasattr(self.predictor, 'lin'):
                    batch_scores = torch.sigmoid(self.predictor.lin(combined)).squeeze()
                else:
                    # ç®€å•çš„ç‚¹ç§¯ç›¸ä¼¼åº¦
                    batch_scores = torch.sum(student_embs * job_embs, dim=-1)
                    batch_scores = torch.sigmoid(batch_scores)
                
                if batch_scores.dim() == 0:
                    batch_scores = batch_scores.unsqueeze(0)
                
                scores.extend(list(zip(batch_jobs, batch_scores.tolist())))
        
        # æŒ‰åˆ†æ•°é™åºæ’åˆ—
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores
    
    # ==================== Layer 3: é‡æ’åºä¸èåˆ ====================
    def fuse_and_explain(
        self,
        student_id: str,
        ranked_jobs: List[Tuple[int, float]],
        top_k: int = 50,
        weights: Tuple[float, float, float] = (0.6, 0.3, 0.1)
    ) -> List[RecommendationResult]:
        """
        Layer 3: ç¥ç»ç¬¦å·èåˆä¸å¯è§£é‡Šæ€§ç”Ÿæˆ
        
        Args:
            student_id: å­¦ç”ŸID
            ranked_jobs: Layer 2çš„æ’åºç»“æœ
            top_k: éœ€è¦èåˆå¤„ç†çš„æ•°é‡
            weights: (deep_weight, skill_weight, rule_weight)
            
        Returns:
            æœ€ç»ˆæ¨èç»“æœåˆ—è¡¨
        """
        w_deep, w_skill, w_rule = weights
        results = []
        
        # åªå¯¹Top-Kè¿›è¡ŒNeo4jæŸ¥è¯¢ä»¥å‡å°‘å‹åŠ›
        for job_idx, deep_score in ranked_jobs[:top_k]:
            job_id = self.job_mapping.get(job_idx, str(job_idx))
            
            # æŸ¥è¯¢æŠ€èƒ½é‡å 
            skill_info = self._query_skill_overlap(student_id, job_id)
            overlap_count = skill_info.get('overlap_count', 0)
            required_count = skill_info.get('required_count', 1)  # é˜²æ­¢é™¤é›¶
            matched_skills = skill_info.get('matched_skills', [])
            
            # è®¡ç®—æŠ€èƒ½å¾—åˆ†
            if required_count > 0:
                skill_score = min(overlap_count / required_count, 1.0)
            else:
                skill_score = 0.0
            
            # è§„åˆ™å¾—åˆ†ï¼ˆå­¦å†åŒ¹é…ç­‰ï¼‰
            rule_score = self._calculate_rule_score(student_id, job_id)
            
            # èåˆå…¬å¼
            final_score = w_deep * deep_score + w_skill * skill_score + w_rule * rule_score
            
            # ç”Ÿæˆè§£é‡Š
            explanation = self._generate_explanation(
                deep_score, skill_score, rule_score, matched_skills
            )
            
            results.append(RecommendationResult(
                job_id=job_id,
                final_score=final_score,
                deep_score=deep_score,
                skill_score=skill_score,
                rule_score=rule_score,
                matched_skills=matched_skills,
                explanation=explanation
            ))
        
        # æŒ‰æœ€ç»ˆå¾—åˆ†é‡æ’åº
        results.sort(key=lambda x: x.final_score, reverse=True)
        return results
    
    def _query_skill_overlap(self, student_id: str, job_id: str) -> Dict:
        """
        æŸ¥è¯¢å­¦ç”Ÿä¸èŒä½çš„æŠ€èƒ½é‡å 
        
        åŒ…å«ä¸¤æ¡è·¯å¾„ï¼š
        1. ç›´æ¥æŠ€èƒ½ï¼šStudent -[:HAS_SKILL]-> Skill
        2. è¯¾ç¨‹èµ‹äºˆï¼šStudent -[:TAKES]-> Course -[:TEACHES_SKILL]-> Skill
        """
        query = """
        // è·¯å¾„1: ç›´æ¥æ‹¥æœ‰çš„æŠ€èƒ½
        MATCH (s:Student {student_id: $stu_id})-[:HAS_SKILL]->(k:Skill)
              <-[:REQUIRES_SKILL]-(j:Job)
        WHERE j.url ENDS WITH $job_suffix
        WITH collect(DISTINCT k.name) as direct_skills
        
        // è·¯å¾„2: é€šè¿‡è¯¾ç¨‹è·å¾—çš„æŠ€èƒ½
        OPTIONAL MATCH (s2:Student {student_id: $stu_id})-[:TAKES]->(c:Course)-[:TEACHES_SKILL]->(k2:Skill)
              <-[:REQUIRES_SKILL]-(j2:Job)
        WHERE j2.url ENDS WITH $job_suffix
        WITH direct_skills, collect(DISTINCT k2.name) as course_skills
        
        // åˆå¹¶æŠ€èƒ½ï¼ˆå»é‡ï¼‰
        WITH direct_skills, course_skills, 
             [x IN direct_skills + course_skills WHERE x IS NOT NULL | x] AS all_skills_raw
        UNWIND all_skills_raw AS skill
        WITH direct_skills, course_skills, collect(DISTINCT skill) AS all_skills
        
        // è·å–èŒä½è¦æ±‚çš„æŠ€èƒ½æ€»æ•°
        OPTIONAL MATCH (j3:Job)-[:REQUIRES_SKILL]->(k3:Skill)
        WHERE j3.url ENDS WITH $job_suffix
        WITH direct_skills, course_skills, all_skills, count(DISTINCT k3) as required_count
        
        RETURN SIZE(all_skills) as overlap_count, 
               all_skills as matched_skills, 
               required_count,
               direct_skills,
               course_skills
        """
        
        # æå–job_idåç¼€ç”¨äºåŒ¹é…
        job_suffix = job_id if '/' not in job_id else job_id.split('/')[-1]
        
        try:
            with self.driver.session() as session:
                result = session.run(
                    query, 
                    stu_id=student_id, 
                    job_suffix=job_suffix
                ).single()
                
                if result:
                    return {
                        'overlap_count': result['overlap_count'] or 0,
                        'matched_skills': result['matched_skills'] or [],
                        'required_count': result['required_count'] or 1,
                        'direct_skills': result['direct_skills'] or [],
                        'course_skills': result['course_skills'] or []
                    }
        except Exception as e:
            # æŸ¥è¯¢å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
            print(f"æŠ€èƒ½åŒ¹é…æŸ¥è¯¢å¤±è´¥: {e}")
            pass
        
        return {'overlap_count': 0, 'matched_skills': [], 'required_count': 1, 'direct_skills': [], 'course_skills': []}
    
    def _calculate_rule_score(self, student_id: str, job_id: str) -> float:
        """
        è®¡ç®—è§„åˆ™å¾—åˆ†ï¼ˆå­¦å†åŒ¹é…ç­‰ï¼‰
        
        ç®€åŒ–å®ç°ï¼šæŸ¥è¯¢å­¦å†æ˜¯å¦åŒ¹é…
        """
        query = """
        MATCH (s:Student {student_id: $stu_id})
        OPTIONAL MATCH (j:Job) WHERE j.url ENDS WITH $job_suffix
        RETURN s.education as stu_edu, j.education as job_edu
        """
        
        job_suffix = job_id if '/' not in job_id else job_id.split('/')[-1]
        
        try:
            with self.driver.session() as session:
                result = session.run(query, stu_id=student_id, job_suffix=job_suffix).single()
                
                if result:
                    stu_edu = result['stu_edu']
                    job_edu = result['job_edu']
                    
                    # å­¦å†ç­‰çº§æ˜ å°„
                    edu_levels = {'å¤§ä¸“': 1, 'æœ¬ç§‘': 2, 'ç¡•å£«': 3, 'åšå£«': 4, 'ä¸é™': 0}
                    
                    stu_level = edu_levels.get(stu_edu, 2)
                    job_level = edu_levels.get(job_edu, 0)
                    
                    # å¦‚æœå­¦å†æ»¡è¶³è¦æ±‚ï¼Œè¿”å›1.0
                    if job_level == 0 or stu_level >= job_level:
                        return 1.0
                    else:
                        return 0.5  # å­¦å†ä¸å®Œå…¨åŒ¹é…
        except:
            pass
        
        return 1.0  # é»˜è®¤åŒ¹é…
    
    def _generate_explanation(
        self,
        deep_score: float,
        skill_score: float,
        rule_score: float,
        matched_skills: List[str]
    ) -> str:
        """ç”Ÿæˆæ¨èç†ç”±æ–‡æ¡ˆ"""
        reasons = []
        
        # æŠ€èƒ½åŒ¹é…ï¼ˆä¼˜å…ˆæ˜¾ç¤ºï¼‰
        if matched_skills:
            if len(matched_skills) <= 3:
                skills_str = ", ".join(matched_skills)
            else:
                skills_str = ", ".join(matched_skills[:3]) + f" ç­‰{len(matched_skills)}é¡¹"
            reasons.append(f"æ‚¨æŒæ¡çš„ [{skills_str}] æŠ€èƒ½ä¸èŒä½è¦æ±‚åŒ¹é…")
        
        # æ·±åº¦å­¦ä¹ åŒ¹é…åº¦
        if deep_score >= 0.8:
            reasons.append("æ·±åº¦å­¦ä¹ åŒ¹é…åº¦æé«˜")
        elif deep_score >= 0.6:
            reasons.append("æ·±åº¦å­¦ä¹ åŒ¹é…åº¦è¾ƒé«˜")
        
        # å­¦å†åŒ¹é…
        if rule_score >= 1.0:
            reasons.append("å­¦å†å®Œå…¨æ»¡è¶³è¦æ±‚")
        
        if reasons:
            return "æ¨èç†ç”±ï¼š" + "ï¼Œ".join(reasons)
        else:
            return "æ¨èç†ç”±ï¼šç»¼åˆè¯„ä¼°é€‚åˆ"
    
    # ==================== ä¸»æ¨èæ¥å£ ====================
    def recommend(
        self,
        student_id: str,
        recall_k: int = 500,
        rank_k: int = 50,
        final_k: int = 10,
        weights: Tuple[float, float, float] = (0.5, 0.35, 0.15),  # è°ƒæ•´ï¼šæ›´é‡è§†æŠ€èƒ½åŒ¹é…
        city: Optional[str] = None,
        skills: List[str] = None
    ) -> List[RecommendationResult]:
        """
        å®Œæ•´çš„ä¸‰å±‚æ¼æ–—æ¨èæµç¨‹
        
        Args:
            student_id: å­¦ç”ŸID
            recall_k: Layer 1 å¬å›æ•°é‡
            rank_k: Layer 2->3 ç²¾æ’æ•°é‡
            final_k: æœ€ç»ˆè¿”å›æ•°é‡
            weights: èåˆæƒé‡ (deep, skill, rule)
            city: åŸå¸‚è¿‡æ»¤
            skills: ç”¨æˆ·æŠ€èƒ½åˆ—è¡¨ï¼ˆç”¨äºå†·å¯åŠ¨ç”¨æˆ·çš„åµŒå…¥ç”Ÿæˆï¼‰
            
        Returns:
            æœ€ç»ˆæ¨èç»“æœåˆ—è¡¨
        """
        print(f"\n{'='*50}")
        print(f"ğŸ¯ ä¸º {student_id} ç”Ÿæˆæ¨è")
        if skills:
            print(f"   ç”¨æˆ·æŠ€èƒ½: {skills[:5]}{'...' if len(skills) > 5 else ''}")
        print(f"{'='*50}")
        
        # Layer 1: å¬å›ï¼ˆä¼ å…¥æŠ€èƒ½ç”¨äºå†·å¯åŠ¨åµŒå…¥ç”Ÿæˆï¼‰
        print(f"ğŸ“¥ Layer 1: å¿«é€Ÿå¬å› (Top-{recall_k})...")
        candidates = self.recall(student_id, recall_k, skills)
        print(f"   å¬å›å€™é€‰: {len(candidates)} ä¸ªèŒä½")

        # åŸå¸‚è¿‡æ»¤
        if city:
            print(f"ğŸ™ï¸  åº”ç”¨åŸå¸‚è¿‡æ»¤: {city}")
            original_count = len(candidates)
            candidates = self._filter_by_city(candidates, city)
            print(f"   è¿‡æ»¤åå‰©ä½™: {len(candidates)} / {original_count}")
            
            if not candidates:
                print("âš ï¸  è­¦å‘Š: åŸå¸‚è¿‡æ»¤åæ— å€™é€‰èŒä½")
                return []
        
        # Layer 2: ç²¾æ’
        print(f"ğŸ”¬ Layer 2: æ·±åº¦å­¦ä¹ ç²¾æ’...")
        ranked = self.rank(student_id, candidates)
        print(f"   ç²¾æ’å®Œæˆ: Top score = {ranked[0][1]:.4f}")
        
        # Layer 3: èåˆ
        print(f"ğŸ”— Layer 3: ç¥ç»ç¬¦å·èåˆ (Top-{rank_k})...")
        results = self.fuse_and_explain(student_id, ranked, rank_k, weights)
        
        # è¿”å›æœ€ç»ˆç»“æœ
        final_results = results[:final_k]
        print(f"âœ… æ¨èå®Œæˆ: è¿”å› {len(final_results)} ä¸ªç»“æœ")
        
        return final_results
    
    def recommend_pure_dl(
        self,
        student_id: str,
        top_k: int = 50,
        city: Optional[str] = None,
        skills: List[str] = None,
        expected_position: str = None,
        education: str = None,
        courses: List[str] = None
    ) -> List[RecommendationResult]:
        """
        çº¯æ·±åº¦å­¦ä¹ æ¨èï¼ˆAIæ¨èæ¨¡å¼ï¼‰
        
        ä½¿ç”¨ Layer 1ï¼ˆå‘é‡å¬å›ï¼‰+ Layer 2ï¼ˆæ·±åº¦å­¦ä¹ ç²¾æ’ï¼‰+ è§„åˆ™åŠ æƒï¼ˆå­¦å†ã€æœŸæœ›èŒä¸šï¼‰
        
        Args:
            student_id: å­¦ç”ŸID
            top_k: è¿”å›æ•°é‡
            city: åŸå¸‚è¿‡æ»¤
            skills: ç”¨æˆ·ç›´æ¥æŠ€èƒ½åˆ—è¡¨
            expected_position: æœŸæœ›èŒä¸š
            education: ç”¨æˆ·å­¦å†
            courses: ç”¨æˆ·å·²ä¿®è¯¾ç¨‹åˆ—è¡¨
            
        Returns:
            æ¨èç»“æœåˆ—è¡¨
        """
        print(f"\n{'='*50}")
        print(f"ğŸ¤– AIæ¨è (çº¯æ·±åº¦å­¦ä¹ æ¨¡å¼) - {student_id}")
        
        # 1. åˆå¹¶ç›´æ¥æŠ€èƒ½ + è¯¾ç¨‹æŠ€èƒ½
        all_skills = list(skills) if skills else []
        if courses:
            course_skills = self._get_course_skills(courses)
            if course_skills:
                # å»é‡åˆå¹¶
                all_skills = list(set(all_skills + course_skills))
                print(f"   è¯¾ç¨‹æŠ€èƒ½: ä» {len(courses)} é—¨è¯¾ç¨‹è·å¾— {len(course_skills)} ä¸ªæŠ€èƒ½")
        
        if all_skills:
            print(f"   æ€»æŠ€èƒ½æ•°: {len(all_skills)} (ç›´æ¥æŠ€èƒ½: {len(skills or [])}, è¯¾ç¨‹æŠ€èƒ½: {len(all_skills) - len(skills or [])})")
        if expected_position:
            print(f"   æœŸæœ›èŒä¸š: {expected_position}")
        if education:
            print(f"   å­¦å†: {education}")
        print(f"{'='*50}")
        
        # Layer 1: å¬å›
        recall_k = min(500, len(self.job_indices))
        print(f"ğŸ“¥ Layer 1: å‘é‡ç›¸ä¼¼åº¦å¬å› (Top-{recall_k})...")
        candidates = self.recall(student_id, recall_k, all_skills)
        print(f"   å¬å›å€™é€‰: {len(candidates)} ä¸ªèŒä½")
        
        # åŸå¸‚è¿‡æ»¤
        if city:
            print(f"ğŸ™ï¸  åº”ç”¨åŸå¸‚è¿‡æ»¤: {city}")
            original_count = len(candidates)
            candidates = self._filter_by_city(candidates, city)
            print(f"   è¿‡æ»¤åå‰©ä½™: {len(candidates)} / {original_count}")
            
            if not candidates:
                print("âš ï¸  è­¦å‘Š: åŸå¸‚è¿‡æ»¤åæ— å€™é€‰èŒä½")
                return []
        
        # Layer 2: ç²¾æ’ - ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹
        print(f"ğŸ”¬ Layer 2: æ·±åº¦å­¦ä¹ ç²¾æ’...")
        ranked = self.rank(student_id, candidates)
        if ranked:
            print(f"   ç²¾æ’å®Œæˆ: Top score = {ranked[0][1]:.4f}")
        
        # Layer 2.5: è§„åˆ™åŠ æƒï¼ˆå­¦å†åŒ¹é…ã€æœŸæœ›èŒä¸šåŒ¹é…ï¼‰
        print(f"ğŸ“ Layer 2.5: è§„åˆ™åŠ æƒ...")
        weighted_results = []
        
        for job_idx, deep_score in ranked:
            job_id = self.job_mapping.get(job_idx, str(job_idx))
            
            # æŸ¥è¯¢èŒä½ä¿¡æ¯
            job_info = self._get_job_info_for_matching(job_id)
            job_title = job_info.get('title', '')
            job_edu = job_info.get('education', '')
            
            # å­¦å†åŠ æƒï¼ˆAIæ¨¡å¼ï¼šé™ä½å¼ºåº¦ï¼Œé¼“åŠ±æ¢ç´¢ï¼‰
            edu_boost = 1.0
            if education and job_edu:
                edu_match = self._calculate_education_match(education, job_edu)
                if edu_match == 'perfect':  # å®Œå…¨åŒ¹é…
                    edu_boost = 1.3  # åŸ1.3
                elif edu_match == 'compatible':  # å…¼å®¹ï¼ˆå­¦å†>=è¦æ±‚ æˆ– ä¸é™ï¼‰
                    edu_boost = 1.1  # åŸ1.1
                else:  # ä¸åŒ¹é…ï¼ˆå­¦å†<è¦æ±‚ï¼‰
                    edu_boost = 0.7  # åŸ0.7ï¼Œé™ä½æƒ©ç½šé¼“åŠ±æ¢ç´¢
            
            # æœŸæœ›èŒä¸šåŠ æƒï¼ˆAIæ¨¡å¼ï¼šå¼±åŒ–é”šå®šï¼Œæ¢ç´¢æ–°æœºä¼šï¼‰
            position_boost = 1.0
            if expected_position and job_title:
                position_match = self._calculate_position_match(expected_position, job_title)
                if position_match >= 0.8:  # é«˜åº¦åŒ¹é…
                    position_boost = 1.4  # åŸ1.5
                elif position_match >= 0.5:  # éƒ¨åˆ†åŒ¹é…
                    position_boost = 1.3  # åŸ1.2
                elif position_match >= 0.3:  # è½»å¾®ç›¸å…³
                    position_boost = 1.1  # åŸ1.1
            
            # è®¡ç®—åŠ æƒå¾—åˆ†
            final_score = deep_score * edu_boost * position_boost
            
            weighted_results.append({
                'job_idx': job_idx,
                'job_id': job_id,
                'deep_score': deep_score,
                'final_score': final_score,
                'edu_boost': edu_boost,
                'position_boost': position_boost,
                'job_title': job_title,
                'job_edu': job_edu
            })
        
        # æŒ‰åŠ æƒåçš„åˆ†æ•°é‡æ–°æ’åº
        weighted_results.sort(key=lambda x: x['final_score'], reverse=True)
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        results = []
        for item in weighted_results[:top_k]:
            job_id = item['job_id']
            
            # æŸ¥è¯¢åŒ¹é…çš„æŠ€èƒ½
            skill_info = self._query_skill_overlap(student_id, job_id)
            matched_skills = skill_info.get('matched_skills', [])
            
            explanation = self._generate_dl_explanation_v2(
                item['deep_score'], 
                item['edu_boost'], 
                item['position_boost'],
                matched_skills,
                education,
                item['job_edu'],
                expected_position,
                item['job_title']
            )
            
            results.append(RecommendationResult(
                job_id=job_id,
                final_score=item['final_score'],
                deep_score=item['deep_score'],
                skill_score=item['position_boost'] - 1.0,  # ç”¨äºå±•ç¤ºæœŸæœ›èŒä¸šåŒ¹é…åº¦
                rule_score=item['edu_boost'] - 1.0,  # ç”¨äºå±•ç¤ºå­¦å†åŒ¹é…åº¦
                matched_skills=matched_skills,
                explanation=explanation
            ))
        
        print(f"âœ… AIæ¨èå®Œæˆ: è¿”å› {len(results)} ä¸ªç»“æœ")
        return results
    
    def _generate_dl_explanation(self, deep_score: float, matched_skills: List[str]) -> str:
        """ç”ŸæˆAIæ¨èçš„è§£é‡Šæ–‡æ¡ˆ"""
        reasons = []
        
        if deep_score >= 0.8:
            reasons.append("æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ¤æ–­åŒ¹é…åº¦æé«˜")
        elif deep_score >= 0.6:
            reasons.append("æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ¤æ–­åŒ¹é…åº¦è¾ƒé«˜")
        elif deep_score >= 0.4:
            reasons.append("æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ¤æ–­åŸºæœ¬åŒ¹é…")
        else:
            reasons.append("æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ¤æ–­å¯èƒ½åŒ¹é…")
        
        if matched_skills:
            if len(matched_skills) <= 3:
                skills_str = ", ".join(matched_skills)
            else:
                skills_str = ", ".join(matched_skills[:3]) + f" ç­‰{len(matched_skills)}é¡¹"
            reasons.append(f"æŠ€èƒ½åŒ¹é…: {skills_str}")
        
        return "AIæ¨èç†ç”±ï¼š" + "ï¼Œ".join(reasons)
    
    def _get_course_skills(self, courses: List[str]) -> List[str]:
        """ä» Neo4j æŸ¥è¯¢è¯¾ç¨‹æ‰€æ•™æˆçš„æŠ€èƒ½"""
        if not courses or not self.driver:
            return []
        
        try:
            with self.driver.session() as session:
                # å°è¯•å¤šç§åŒ¹é…æ–¹å¼
                query = """
                MATCH (c:Course)-[:TEACHES_SKILL]->(s:Skill)
                WHERE c.name IN $courses OR c.course_name IN $courses
                RETURN DISTINCT s.name as skill
                """
                result = session.run(query, courses=courses)
                skills = [record["skill"] for record in result if record["skill"]]
                return skills
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢è¯¾ç¨‹æŠ€èƒ½å¤±è´¥: {e}")
            return []
    
    def _get_job_info_for_matching(self, job_id: str) -> dict:
        """è·å–èŒä½çš„æ ‡é¢˜å’Œå­¦å†è¦æ±‚"""
        if not self.driver:
            return {}
        
        try:
            with self.driver.session() as session:
                query = """
                MATCH (j:Job)
                WHERE j.url = $job_id OR j.url ENDS WITH $job_id
                RETURN j.title as title, j.education as education
                LIMIT 1
                """
                result = session.run(query, job_id=job_id)
                record = result.single()
                if record:
                    return {
                        'title': record['title'] or '',
                        'education': record['education'] or ''
                    }
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢èŒä½ä¿¡æ¯å¤±è´¥: {e}")
        
        return {'title': '', 'education': ''}
    
    def _calculate_education_match(self, user_edu: str, job_edu: str) -> str:
        """è®¡ç®—å­¦å†åŒ¹é…ç¨‹åº¦"""
        # å­¦å†ç­‰çº§æ˜ å°„
        edu_levels = {
            'é«˜ä¸­': 1, 'ä¸­ä¸“': 1, 'ä¸­æŠ€': 1,
            'å¤§ä¸“': 2, 'ä¸“ç§‘': 2,
            'æœ¬ç§‘': 3, 'å­¦å£«': 3,
            'ç¡•å£«': 4, 'ç ”ç©¶ç”Ÿ': 4,
            'åšå£«': 5,
            'ä¸é™': 0, 'æ— è¦æ±‚': 0, '': 0
        }
        
        user_level = edu_levels.get(user_edu, 3)  # é»˜è®¤æœ¬ç§‘
        job_level = edu_levels.get(job_edu, 0)  # é»˜è®¤ä¸é™
        
        if job_level == 0:  # ä¸é™
            return 'compatible'
        elif user_level == job_level:  # å®Œå…¨åŒ¹é…
            return 'perfect'
        elif user_level >= job_level:  # å­¦å†é«˜äºè¦æ±‚
            return 'compatible'
        else:  # å­¦å†ä½äºè¦æ±‚
            return 'mismatch'
    
    def _calculate_position_match(self, expected: str, job_title: str) -> float:
        """è®¡ç®—æœŸæœ›èŒä¸šä¸èŒä½æ ‡é¢˜çš„åŒ¹é…åº¦"""
        if not expected or not job_title:
            return 0.0
        
        expected = expected.lower()
        job_title = job_title.lower()
        
        # å®Œå…¨åŒ…å«
        if expected in job_title or job_title in expected:
            return 1.0
        
        # å…³é”®è¯åŒ¹é…
        # å®šä¹‰èŒä½å…³é”®è¯æ˜ å°„
        position_keywords = {
            'å‰ç«¯': ['å‰ç«¯', 'frontend', 'web', 'vue', 'react', 'javascript', 'js', 'css', 'html', 'h5'],
            'åç«¯': ['åç«¯', 'backend', 'java', 'python', 'go', 'golang', 'php', 'node', 'spring', 'django'],
            'å…¨æ ˆ': ['å…¨æ ˆ', 'fullstack', 'å…¨ç«¯'],
            'ç®—æ³•': ['ç®—æ³•', 'algorithm', 'ai', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'ml', 'deep learning', 'dl', 'æ·±åº¦å­¦ä¹ '],
            'æ•°æ®': ['æ•°æ®', 'data', 'å¤§æ•°æ®', 'hadoop', 'spark', 'etl', 'æ•°ä»“', 'bi', 'åˆ†æ'],
            'æµ‹è¯•': ['æµ‹è¯•', 'test', 'qa', 'quality'],
            'è¿ç»´': ['è¿ç»´', 'devops', 'sre', 'ops', 'äº‘', 'cloud'],
            'äº§å“': ['äº§å“', 'product', 'pm'],
            'è®¾è®¡': ['è®¾è®¡', 'design', 'ui', 'ux', 'äº¤äº’'],
            'android': ['android', 'å®‰å“', 'kotlin'],
            'ios': ['ios', 'swift', 'objective-c', 'oc'],
            'åµŒå…¥å¼': ['åµŒå…¥å¼', 'embedded', 'å•ç‰‡æœº', 'mcu', 'stm32', 'arm'],
            'æ¸¸æˆ': ['æ¸¸æˆ', 'game', 'unity', 'unreal', 'u3d', 'ue4'],
        }
        
        # æ‰¾åˆ°æœŸæœ›èŒä¸šå¯¹åº”çš„å…³é”®è¯åˆ—è¡¨
        expected_keywords = []
        for category, keywords in position_keywords.items():
            if any(kw in expected for kw in keywords):
                expected_keywords.extend(keywords)
        
        if not expected_keywords:
            # ä½¿ç”¨åŸå§‹æœŸæœ›èŒä¸šä½œä¸ºå…³é”®è¯
            expected_keywords = expected.split()
        
        # è®¡ç®—åŒ¹é…åº¦
        match_count = sum(1 for kw in expected_keywords if kw in job_title)
        if match_count > 0:
            return min(match_count / len(expected_keywords), 1.0)
        
        return 0.0
    
    def _generate_dl_explanation_v2(
        self, 
        deep_score: float, 
        edu_boost: float, 
        position_boost: float,
        matched_skills: List[str],
        user_edu: str,
        job_edu: str,
        expected_position: str,
        job_title: str
    ) -> str:
        """ç”Ÿæˆ AI æ¨èçš„è¯¦ç»†è§£é‡Š"""
        reasons = []
        
        # æœŸæœ›èŒä¸šåŒ¹é…è¯´æ˜
        if position_boost >= 1.5:
            reasons.append(f"èŒä½ä¸æ‚¨çš„æœŸæœ›ã€Œ{expected_position}ã€é«˜åº¦åŒ¹é…")
        elif position_boost >= 1.2:
            reasons.append(f"èŒä½ä¸æ‚¨çš„æœŸæœ›ã€Œ{expected_position}ã€ç›¸å…³")
        
        # å­¦å†åŒ¹é…è¯´æ˜
        if edu_boost >= 1.3:
            reasons.append(f"å­¦å†å®Œå…¨åŒ¹é…ï¼ˆ{user_edu}ï¼‰")
        elif edu_boost >= 1.1:
            reasons.append(f"å­¦å†ç¬¦åˆè¦æ±‚")
        elif edu_boost < 1.0:
            reasons.append(f"å­¦å†å¯èƒ½ä¸è¶³ï¼ˆèŒä½è¦æ±‚{job_edu}ï¼‰")
        
        # æ·±åº¦å­¦ä¹ å¾—åˆ†è¯´æ˜
        if deep_score >= 0.7:
            reasons.append("AIæ¨¡å‹åˆ¤æ–­åŒ¹é…åº¦é«˜")
        elif deep_score >= 0.5:
            reasons.append("AIæ¨¡å‹åˆ¤æ–­åŸºæœ¬åŒ¹é…")
        
        # æŠ€èƒ½åŒ¹é…
        if matched_skills:
            if len(matched_skills) <= 3:
                skills_str = ", ".join(matched_skills)
            else:
                skills_str = ", ".join(matched_skills[:3]) + f" ç­‰{len(matched_skills)}é¡¹"
            reasons.append(f"æŠ€èƒ½åŒ¹é…: {skills_str}")
        
        return "AIæ¨èï¼š" + "ï¼Œ".join(reasons) if reasons else "AIæ¨è"
    
    def close(self):
        """å…³é—­èµ„æº"""
        if self.driver:
            self.driver.close()

    def _filter_by_city(self, job_indices: List[int], city: str) -> List[int]:
        """æ ¹æ®åŸå¸‚è¿‡æ»¤èŒä½å€™é€‰"""
        valid_indices = []
        # è½¬æ¢ä¸ºIDåˆ—è¡¨
        job_ids = []
        idx_map = {} # job_id -> list of indices (in case of duplicates, though unlikely)
        
        for idx in job_indices:
            if idx in self.job_mapping:
                jid = self.job_mapping[idx]
                job_ids.append(jid)
                idx_map[jid] = idx
        
        if not job_ids:
            print("âš ï¸  _filter_by_city: job_ids is empty after mapping")
            return []

        print(f"DEBUG _filter_by_city: Filtering {len(job_ids)} jobs for city '{city}'")
        # Sample job IDs
        print(f"DEBUG _filter_by_city: Sample job_ids: {job_ids[:3]}")

        # æ‰¹é‡æŸ¥è¯¢Neo4j - æ£€æŸ¥å…¬å¸ä½äºè¯¥åŸå¸‚çš„èŒä½
        query = """
        MATCH (j:Job)-[:OFFERED_BY]->(:Company)-[:LOCATED_IN]->(:City {name: $city})
        WHERE j.url IN $job_ids
        RETURN j.url AS job_id
        """
        
        try:
            with self.driver.session() as session:
                result = session.run(query, city=city, job_ids=job_ids)
                valid_job_ids = {record["job_id"] for record in result}
                print(f"DEBUG _filter_by_city: Found {len(valid_job_ids)} valid jobs in {city}")
                
                if len(valid_job_ids) == 0:
                    print(f"âš ï¸ WARNING: No jobs found in {city}! Check if city name matches Neo4j data.")
                    # æ£€æŸ¥åŸå¸‚æ˜¯å¦å­˜åœ¨
                    city_check = session.run("MATCH (c:City {name: $city}) RETURN c.name", city=city).single()
                    if city_check:
                        print(f"   City '{city}' exists in Neo4j")
                    else:
                        print(f"   âŒ City '{city}' does NOT exist in Neo4j!")
                
                # è½¬æ¢å›ç´¢å¼•
                for jid in valid_job_ids:
                    if jid in idx_map:
                        valid_indices.append(idx_map[jid])
                        
        except Exception as e:
            print(f"âŒ åŸå¸‚è¿‡æ»¤å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return []
        
        print(f"DEBUG _filter_by_city: Returning {len(valid_indices)} valid indices")
        return valid_indices


# ==================== ä¾¿æ·å‡½æ•° ====================
def create_recommender_from_trained_model(
    model_path: str = 'è¾“å‡º/æ¨¡å‹æƒé‡/graphsage_model.pth',
    data_path: str = 'graph_data.pt',
    neo4j_uri: str = 'bolt://localhost:7687',
    neo4j_user: str = 'neo4j',
    neo4j_password: str = 'TYH041113'
) -> HybridRecommender:
    """
    ä»è®­ç»ƒå¥½çš„æ¨¡å‹åˆ›å»ºæ··åˆæ¨èå™¨
    """
    from model import RecommenderModel
    
    # åŠ è½½æ•°æ®
    print("ğŸ“‚ åŠ è½½å›¾æ•°æ®...")
    data = torch.load(data_path, weights_only=False)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ§  åŠ è½½æ¨¡å‹æƒé‡...")
    model = RecommenderModel(data.metadata(), hidden_channels=64, out_channels=32)
    model.load_state_dict(torch.load(model_path, weights_only=True))
    model.eval()
    
    # è·å–èŠ‚ç‚¹åµŒå…¥
    print("ğŸ”— ç”ŸæˆèŠ‚ç‚¹åµŒå…¥...")
    with torch.no_grad():
        x_dict = model.encoder(data.x_dict, data.edge_index_dict)
    
    # æ„å»ºåµŒå…¥å­—å…¸
    node_embeddings = {}
    
    # StudentåµŒå…¥
    student_map = data['student'].node_map
    for stu_id, idx in student_map.items():
        node_embeddings[stu_id] = x_dict['student'][idx]
    print(f"   StudentåµŒå…¥: {len(student_map)} ä¸ª")
    
    # JobåµŒå…¥
    job_map = data['job'].node_map
    for job_id, idx in job_map.items():
        node_embeddings[job_id] = x_dict['job'][idx]
    print(f"   JobåµŒå…¥: {len(job_map)} ä¸ª")
    
    # æ„å»ºJobç´¢å¼•æ˜ å°„
    job_mapping = {idx: job_id for job_id, idx in job_map.items()}
    
    # å…ˆè¿æ¥Neo4jï¼ˆç”¨äºæŸ¥è¯¢æŠ€èƒ½åˆ—è¡¨ï¼‰
    print("ğŸ”Œ è¿æ¥Neo4j...")
    driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
    
    # SkillåµŒå…¥ï¼ˆå…³é”®ï¼šç”¨äºå†·å¯åŠ¨ç”¨æˆ·çš„åµŒå…¥ç”Ÿæˆï¼‰
    # ä» Neo4j æŸ¥è¯¢æ‰€æœ‰æŠ€èƒ½åç§°ï¼ŒæŒ‰å­—æ¯é¡ºåºä¸ data_loader ä¸­çš„ skill_encoder å¯¹åº”
    try:
        with driver.session() as session:
            result = session.run("MATCH (s:Skill) RETURN s.name AS name ORDER BY s.name")
            skill_names = [record["name"] for record in result]
        
        if 'skill' in x_dict and skill_names:
            skill_embs = x_dict['skill']
            # åŠ è½½èƒ½åŒ¹é…åˆ°çš„æŠ€èƒ½åµŒå…¥ï¼ˆå…è®¸å°‘é‡æ•°é‡å·®å¼‚ï¼‰
            loaded_count = 0
            for i, skill_name in enumerate(skill_names):
                if i < skill_embs.shape[0]:
                    node_embeddings[skill_name] = skill_embs[i]
                    loaded_count += 1
            print(f"   SkillåµŒå…¥: {loaded_count} ä¸ª (Neo4jæœ‰{len(skill_names)}ä¸ª)")
    except Exception as e:
        print(f"   âš ï¸ SkillåµŒå…¥åŠ è½½å¤±è´¥: {e}")
    
    # åˆ›å»ºæ¨èå™¨
    recommender = HybridRecommender(
        node_embeddings=node_embeddings,
        link_predictor=model.predictor,
        neo4j_driver=driver,
        job_mapping=job_mapping,
        embedding_dim=32
    )
    
    return recommender


# ==================== æµ‹è¯•ä»£ç  ====================
if __name__ == "__main__":
    print("="*60)
    print("ğŸš€ ä¸‰å±‚æ¼æ–—å¼æ··åˆæ¨èç³»ç»Ÿæµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºæ¨èå™¨
    recommender = create_recommender_from_trained_model()
    
    # æµ‹è¯•æ¨è
    test_students = ['STU0001', 'STU0010', 'STU0050']
    
    for stu_id in test_students:
        results = recommender.recommend(stu_id, recall_k=500, rank_k=50, final_k=5)
        
        print(f"\nğŸ“‹ {stu_id} æ¨èç»“æœ:")
        print("-" * 60)
        for i, rec in enumerate(results, 1):
            print(f"\n  {i}. {rec.job_id[-25:]}")
            print(f"     æœ€ç»ˆå¾—åˆ†: {rec.final_score:.4f}")
            print(f"     æ·±åº¦å­¦ä¹ : {rec.deep_score:.4f} | æŠ€èƒ½åŒ¹é…: {rec.skill_score:.4f} | è§„åˆ™: {rec.rule_score:.4f}")
            print(f"     {rec.explanation}")
    
    recommender.close()
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("="*60)
